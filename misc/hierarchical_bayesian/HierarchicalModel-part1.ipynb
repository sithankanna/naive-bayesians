{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simpl(er) Introduction to Hierarchical Linear Regressions \n",
    "### Naive Bayesians, 2020\n",
    "\n",
    "By using synthetically generated data we will compare pooled, unpooled (individual) models and Bayesian hierarchical linear regressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from typing import Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "plt.rcParams[\"font.size\"] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assume there are 2 sites with different regression coefficients \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    n = 20\n",
    "    beta_opt_1 = 2.0\n",
    "    beta_opt_2 = -5.0\n",
    "\n",
    "    std_noise_x = 0.5\n",
    "    std_noise_y = 1\n",
    "\n",
    "    x_1 = std_noise_x * np.random.randn(n)\n",
    "    y_1 = beta_opt_1 * x_1 + std_noise_y * np.random.randn(n)\n",
    "\n",
    "    x_2 = std_noise_x * np.random.randn(n)\n",
    "    y_2 = beta_opt_2 * x_2 + std_noise_y * np.random.randn(n)\n",
    "\n",
    "    df_1 = pd.DataFrame({\"y\": y_1, \"x\": x_1}).assign(\n",
    "        **{\"site\": \"site_A\", \"site_idx\": 0}\n",
    "    )\n",
    "    df_2 = pd.DataFrame({\"y\": y_2, \"x\": x_2}).assign(\n",
    "        **{\"site\": \"site_B\", \"site_idx\": 1}\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df_1, df_2], axis=\"rows\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "data = create_dataset()\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sites = len(data[\"site\"].unique())\n",
    "site_indices = data[\"site_idx\"].values\n",
    "\n",
    "print(f\"Number of sites: {n_sites}\\n\")\n",
    "print(\"Indicator to match each data point to a site:\\n\", site_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooled model: Fitting a regression for both models\n",
    "pooled_lin_mod = LinearRegression(fit_intercept=False)\n",
    "pooled_lin_mod.fit(data[[\"x\"]], data[[\"y\"]])\n",
    "print(\"Pooled model for both sites\", pooled_lin_mod.coef_[0])\n",
    "\n",
    "\n",
    "# Fitting a regular regression model for each site separately\n",
    "for site_name, site_data in data.groupby(\"site\"):\n",
    "    lin_mod = LinearRegression(fit_intercept=False)\n",
    "    lin_mod.fit(site_data[[\"x\"]], site_data[[\"y\"]])\n",
    "    print(f\"Individual model for: {site_name}\", lin_mod.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as pooled_model:\n",
    "\n",
    "    # Define priors\n",
    "    sigma_pooled = pm.HalfCauchy(\"sigma_pooled\", beta=5)\n",
    "    beta_pooled = pm.Normal(\"beta_pooled\", mu=0, sd=20)\n",
    "\n",
    "    # Define likelihood\n",
    "    likelihood = pm.Normal(\n",
    "        \"y_hat\", mu=beta_pooled * data[\"x\"], sd=sigma_pooled, observed=data[\"y\"]\n",
    "    )\n",
    "\n",
    "    # Inference!\n",
    "    trace_pooled = pm.sample(draws=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_beta_pooled = trace_pooled.get_values(\"beta_pooled\", burn=1000, chains=[0])\n",
    "fig = ff.create_distplot(\n",
    "    posterior_beta_pooled.reshape(1, -1),\n",
    "    [\"Pooled Estimate\"],\n",
    "    show_hist=False,\n",
    "    show_rug=False,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posteriors = posterior_beta_pooled.copy().reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual (Unpooled) Model\n",
    "\n",
    "\n",
    "Instead of specifying 2 separate models for each site, we can build a \"single\" model but ensure that the data for each site is fitted independently. This is done using the array called `site_indices` which specifies data points to the sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as individual_model:\n",
    "\n",
    "    # Define priors now with mu\n",
    "    sigma_individual = pm.HalfCauchy(\"sigma_individual\", beta=5, shape=n_sites)\n",
    "    beta_individual = pm.Normal(\"beta_individual\", mu=0, sd=20, shape=n_sites)\n",
    "\n",
    "    # Define likelihood\n",
    "    likelihood = pm.Normal(\n",
    "        \"y_individual\",\n",
    "        mu=beta_individual[site_indices] * data[\"x\"],\n",
    "        sd=sigma_individual[site_indices],\n",
    "        observed=data[\"y\"],\n",
    "    )\n",
    "\n",
    "    # Inference!\n",
    "    trace_individual = pm.sample(draws=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_beta_individual = trace_individual.get_values(\n",
    "    \"beta_individual\", burn=1000, chains=[0]\n",
    ")\n",
    "\n",
    "all_posteriors = np.concatenate([all_posteriors, posterior_beta_individual.T])\n",
    "\n",
    "\n",
    "fig = ff.create_distplot(\n",
    "    all_posteriors,\n",
    "    [\"Pooled\", \"Individual Estimates_A\", \"Individual Estimates_B\"],\n",
    "    show_hist=False,\n",
    "    show_rug=False,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_beta_pooled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as hierarchical_model:\n",
    "\n",
    "    sigma_hierarchical = pm.HalfCauchy(\"sigma_hierarchical\", beta=5, shape=n_sites)\n",
    "\n",
    "    # The step that makes it hierarchical\n",
    "    # We only assume beta is linked to the global\n",
    "    mu_global = pm.Normal(\"mu_global\", mu=0, sd=1)\n",
    "    #     sd_global = pm.HalfCauchy(\"sd_global\", beta=0.1)\n",
    "    beta_hierarchical = pm.Normal(\n",
    "        \"beta_hierarchical\", mu=mu_global, sd=0.5, shape=n_sites\n",
    "    )\n",
    "\n",
    "    # Define likelihood\n",
    "    likelihood = pm.Normal(\n",
    "        \"y_hierarchical\",\n",
    "        mu=beta_hierarchical[site_indices] * data[\"x\"],\n",
    "        sigma=sigma_hierarchical[site_indices],\n",
    "        observed=data[\"y\"],\n",
    "    )\n",
    "\n",
    "    # Inference!\n",
    "    trace_hierarchical = pm.sample(draws=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_beta_hierarchical = trace_hierarchical.get_values(\n",
    "    \"beta_hierarchical\", burn=1000, chains=[1]\n",
    ")\n",
    "\n",
    "all_posteriors = np.concatenate([all_posteriors, posterior_beta_hierarchical.T])\n",
    "\n",
    "\n",
    "fig = ff.create_distplot(\n",
    "    all_posteriors,\n",
    "    [\"Pooled\", \"Individual Estimates_A\", \"Individual Estimates_B\"]\n",
    "    + [\"Hierarchical Estimates_A\", \"Hierarchical Estimates_B\"],\n",
    "    show_hist=False,\n",
    "    show_rug=False,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.add_trace(\n",
    "#       go.Scatter(\n",
    "#                x=df_posterior.index,\n",
    "#                y=df_posterior[col],\n",
    "#                name=\"lala\")\n",
    "\n",
    "# layout = go.Layout(\n",
    "#     title=\"\",\n",
    "#     font=dict(family=\"Arial\", size=14),\n",
    "#     paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "#     plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "# )\n",
    "\n",
    "\n",
    "# fig = go.Figure(layout=layout)\n",
    "# fig.update_layout(title=\"Title\")\n",
    "# fig.update_xaxes(linecolor=\"black\", title=\"Beta\", showgrid=True, gridcolor=\"LightGray\",)\n",
    "# fig.update_yaxes(ticksuffix=\"\", linecolor=\"black\", title=\"Density\",)\n",
    "# fig.show()\n",
    "\n",
    "data_radon = pd.read_csv(pm.get_data(\"radon.csv\"))\n",
    "# data_radon[\"log_radon\"] = data_radon[\"log_radon\"].astype(theano.config.floatX)\n",
    "# county_names = data_radon.county.unique()\n",
    "# county_idx = data_radon.county_code.values\n",
    "data_radon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_radon.county_code.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as unpooled_model:\n",
    "\n",
    "    # Independent parameters for each county\n",
    "    b = pm.Normal(\"b\", 0, sigma=100, shape=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[[0, 0, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi all, \n",
    "\n",
    "I’ve attempted to create the simplest possible example illustrate hierarchical models for linear regression (even simpler than Gellman et. al.’s [Radon Gas case study](https://docs.pymc.io/notebooks/GLM-hierarchical.html)). \n",
    "\n",
    "**Problem Setup**\n",
    "The data has 2 univariate Regressions (scalar regression coefficient + no intercept) \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{1} {} & \\sim \\text{Normal}(\\mu = 0, \\sigma^2 = 0.25)  \\\\\n",
    "x_{2} {} & \\sim \\text{Normal}(\\mu = 0, \\sigma^2 = 0.25)  \\\\\n",
    "\\eta {} & \\sim \\text{Normal}(\\mu = 0, \\sigma^2 = 1)  \\\\\n",
    "\\beta_1 {} & =  2, \\hspace{2mm} \\beta_2 = -5 \\\\\n",
    "y_1 {} & = \\beta_1x_1 + \\eta \\\\\n",
    "y_2 {} & = \\beta_2x_1 + \\eta \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Then I concatenated $y_1, y_2$ and $x_1, x_2$ into a single vectors e.g. $\\mathbf{y} = [y_1^{(0)} \\dots y_2^{N_1}, y_2^{(0)} \\dots y_2^{N_2}]$ and labelled added an inidcator variable. \n",
    "\n",
    "\n",
    "\n",
    "Then, I performed inference using 3 different schemes (similar to the Radon example) \n",
    "* Pooled\n",
    "* Unpooled (Individual regressions for $y_1$, and $y_2$)\n",
    "* Hierarachical Regression\n",
    "\n",
    "Pooled\n",
    "```python\n",
    "with pm.Model() as pooled_model:\n",
    "\n",
    "    # Define priors\n",
    "    sigma_pooled = pm.HalfCauchy(\"sigma_pooled\", beta=5)\n",
    "    beta_pooled = pm.Normal(\"beta_pooled\", mu=0, sd=20)\n",
    "\n",
    "    # Define likelihood\n",
    "    likelihood = pm.Normal(\n",
    "        \"y_hat\", mu=beta_pooled * data[\"x\"], sd=sigma_pooled, observed=data[\"y\"]\n",
    "    )\n",
    "\n",
    "    # Inference!\n",
    "    trace_pooled = pm.sample(draws=3000)\n",
    "    \n",
    "    # Getting one chain\n",
    "    posterior_beta_pooled = trace_pooled.get_values(\"beta_pooled\", burn=1000, chains=[0])\n",
    "\n",
    "```\n",
    "Unpooled\n",
    "\n",
    "```python\n",
    "with pm.Model() as individual_model:\n",
    "\n",
    "    # Define priors now with mu\n",
    "    sigma_individual = pm.HalfCauchy(\"sigma_individual\", beta=5, shape=n_sites)\n",
    "    beta_individual = pm.Normal(\"beta_individual\", mu=0, sd=20, shape=n_sites)\n",
    "\n",
    "    # Define likelihood\n",
    "    likelihood = pm.Normal(\n",
    "        \"y_individual\",\n",
    "        mu=beta_individual[site_indices] * data[\"x\"],\n",
    "        sd=sigma_individual[site_indices],\n",
    "        observed=data[\"y\"],\n",
    "    )\n",
    "\n",
    "    # Inference!\n",
    "    trace_individual = pm.sample(draws=3000)\n",
    "    \n",
    "    posterior_beta_individual = trace_individual.get_values(\n",
    "        \"beta_individual\", burn=1000, chains=[0]\n",
    "    )\n",
    "```\n",
    "Hierarachical\n",
    "```python\n",
    "with pm.Model() as hierarchical_model:\n",
    "\n",
    "    sigma_hierarchical = pm.HalfCauchy(\"sigma_hierarchical\", beta=5, shape=n_sites)\n",
    "\n",
    "    # The step that makes it hierarchical\n",
    "    # We only assume beta is linked to the global\n",
    "    mu_global = pm.Normal(\"mu_global\", mu=0, sd=0.1)\n",
    "    sd_global = pm.HalfCauchy(\"sd_global\", beta=0.1)\n",
    "    beta_hierarchical = pm.Normal(\n",
    "        \"beta_hierarchical\", mu=mu_global, sd=sd_global, shape=n_sites\n",
    "    )\n",
    "\n",
    "    # Define likelihood\n",
    "    likelihood = pm.Normal(\n",
    "        \"y_hierarchical\",\n",
    "        mu=beta_hierarchical[site_indices] * data[\"x\"],\n",
    "        sigma=sigma_hierarchical[site_indices],\n",
    "        observed=data[\"y\"],\n",
    "    )\n",
    "\n",
    "    # Inference!\n",
    "    trace_hierarchical = pm.sample(draws=3000)\n",
    "    \n",
    "    posterior_beta_hierarchical = trace_hierarchical.get_values(\n",
    "        \"beta_hierarchical\", burn=1000, chains=[1]\n",
    "    )\n",
    "```\n",
    "\n",
    "The goal of the excercies was to show that the hierarchical estimates sits somewhere in between the pooled and individual estimates. And this difference is effected by a few things \n",
    "\n",
    "1) The confidence in the hyper-prior (paramet\n",
    "2) The amount of data available for the different \"sites\" (i.e. confidence in the data)\n",
    "\n",
    "\n",
    "But I find the hierarchical model to always yield posteriors closer to the individual estimates. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
